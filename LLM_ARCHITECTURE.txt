```
╔═══════════════════════════════════════════════════════════════════════╗
║                  LLM Integration Architecture                         ║
╚═══════════════════════════════════════════════════════════════════════╝

┌─────────────────────────────────────────────────────────────────────┐
│                         CLIENT APPLICATIONS                         │
│  (Web Apps, Mobile Apps, CLI Tools, Other Services)                │
└────────────────────────────┬────────────────────────────────────────┘
                             │
                             │ HTTP Requests
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    FastAPI Server (main.py)                         │
│                     http://localhost:8080                           │
│                                                                     │
│  ┌──────────────────────────────────────────────────────────────┐ │
│  │  Existing Routers                                            │ │
│  │  • /v1/oauth/* (OAuth endpoints)                             │ │
│  │  • /v1/users/* (User management)                             │ │
│  │  • /v1/messages/* (Email sending)                            │ │
│  │  • /v1/reports/* (Analytics)                                 │ │
│  └──────────────────────────────────────────────────────────────┘ │
│                                                                     │
│  ┌──────────────────────────────────────────────────────────────┐ │
│  │  NEW: LLM Router (from temp.py)                              │ │
│  │  • POST /llm/inference                                       │ │
│  │  • POST /llm/execute-action                                  │ │
│  │  • GET  /llm/capabilities                                    │ │
│  └──────────────────────────────────────────────────────────────┘ │
└────────────────────────┬────────────────────┬────────────────────────┘
                         │                    │
                         │                    │
              ┌──────────▼────────┐  ┌────────▼─────────┐
              │   LLM Inference   │  │  EmailMCP        │
              │   (temp.py)       │  │  Services        │
              │                   │  │                  │
              │ • Process prompts │  │ • Send emails    │
              │ • Understand      │  │ • Get analytics  │
              │   intent          │  │ • Check status   │
              │ • Suggest actions │  │ • OAuth flow     │
              └──────────┬────────┘  └────────▲─────────┘
                         │                    │
                         │  Execute Action    │
                         └────────────────────┘


╔═══════════════════════════════════════════════════════════════════════╗
║                        Request Flow Example                           ║
╚═══════════════════════════════════════════════════════════════════════╝

1. LLM Inference Request
   ┌──────────────────────────────────────────────────────────────────┐
   │ POST /llm/inference                                              │
   │ Headers:                                                         │
   │   X-API-Key: llm-api-key                                        │
   │ Body:                                                            │
   │   {                                                              │
   │     "prompt": "Send email to user about monthly analytics",     │
   │     "user_id": "user123"                                        │
   │   }                                                              │
   └──────────────────────────────────────────────────────────────────┘
                                   ↓
   ┌──────────────────────────────────────────────────────────────────┐
   │ LLM processes prompt and returns:                                │
   │ {                                                                │
   │   "response": "I'll help you with the monthly analytics...",    │
   │   "action": "get_analytics",                                    │
   │   "parameters": {"time_range": "last_30_days"}                  │
   │ }                                                                │
   └──────────────────────────────────────────────────────────────────┘

2. Execute Action
   ┌──────────────────────────────────────────────────────────────────┐
   │ POST /llm/execute-action                                         │
   │ Headers:                                                         │
   │   X-API-Key: llm-api-key                                        │
   │   X-MCP-API-Key: mcp-api-key                                    │
   │ Body:                                                            │
   │   {                                                              │
   │     "action_type": "get_analytics",                             │
   │     "user_id": "user123",                                       │
   │     "parameters": {}                                            │
   │   }                                                              │
   └──────────────────────────────────────────────────────────────────┘
                                   ↓
   ┌──────────────────────────────────────────────────────────────────┐
   │ Internally calls EmailMCP API:                                   │
   │ GET /v1/reports/users/user123                                   │
   │ Authorization: Bearer mcp-api-key                                │
   └──────────────────────────────────────────────────────────────────┘
                                   ↓
   ┌──────────────────────────────────────────────────────────────────┐
   │ Returns analytics data to client:                                │
   │ {                                                                │
   │   "status": "success",                                           │
   │   "result": {                                                    │
   │     "total_emails": 42,                                          │
   │     "successful": 40,                                            │
   │     "failed": 2                                                  │
   │   }                                                              │
   │ }                                                                │
   └──────────────────────────────────────────────────────────────────┘


╔═══════════════════════════════════════════════════════════════════════╗
║                          Security Model                               ║
╚═══════════════════════════════════════════════════════════════════════╝

┌─────────────────────────────────────────────────────────────────────┐
│                      Dual API Key System                            │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  1. X-API-Key (LLM Access)                                         │
│     • Authenticates LLM client                                     │
│     • Required for /llm/* endpoints                                │
│     • Controls who can use LLM features                            │
│                                                                     │
│  2. X-MCP-API-Key (EmailMCP Access)                               │
│     • Authenticates against EmailMCP service                       │
│     • Required for execute-action endpoint                         │
│     • Controls access to email operations                          │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘


╔═══════════════════════════════════════════════════════════════════════╗
║                        Files Created/Modified                         ║
╚═══════════════════════════════════════════════════════════════════════╝

NEW FILES:
  📄 temp.py (244 lines)
     • LLMRequest/Response models
     • llm_inference() function (mock, ready for real LLM)
     • /llm/inference endpoint
     • /llm/execute-action endpoint
     • /llm/capabilities endpoint

  📄 LLM_INTEGRATION.md (362 lines)
     • Complete integration guide
     • API endpoint documentation
     • Examples for Python, JavaScript, cURL
     • Integration with OpenAI, Claude, local models
     • Security configuration
     • Troubleshooting guide

  📄 examples/llm_integration_example.py (166 lines)
     • Working example code
     • LLM inference example
     • Action execution example
     • Full workflow demonstration

MODIFIED FILES:
  📝 src/mcp/main.py
     • Import temp.py LLM router
     • Add sys.path configuration
     • Include LLM router in app

  📝 README.md
     • Added LLM integration to features
     • Added link to LLM_INTEGRATION.md


╔═══════════════════════════════════════════════════════════════════════╗
║                           Quick Start                                 ║
╚═══════════════════════════════════════════════════════════════════════╝

1. Start the server:
   uvicorn src.mcp.main:app --host 0.0.0.0 --port 8080

2. Check LLM capabilities:
   curl http://localhost:8080/llm/capabilities

3. Test inference:
   curl -X POST http://localhost:8080/llm/inference \
     -H "X-API-Key: test-key" \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Check my emails", "user_id": "user123"}'

4. Run the example:
   python3 examples/llm_integration_example.py

5. Customize for your LLM:
   Edit temp.py, replace llm_inference() with your LLM API calls


╔═══════════════════════════════════════════════════════════════════════╗
║                         Success Metrics                               ║
╚═══════════════════════════════════════════════════════════════════════╝

✅ Server starts successfully with LLM integration
✅ All 3 LLM endpoints are accessible
✅ Example script runs without errors
✅ Integration with EmailMCP service verified
✅ Documentation is complete and comprehensive
✅ Code is minimal and focused (only necessary changes)
✅ No breaking changes to existing functionality
✅ Ready for real LLM integration (OpenAI, Claude, etc.)


╔═══════════════════════════════════════════════════════════════════════╗
║                      Next Steps for Users                             ║
╚═══════════════════════════════════════════════════════════════════════╝

1. ✅ Integration Complete - LLM server is connected to EmailMCP
2. 📖 Read LLM_INTEGRATION.md for detailed documentation
3. 🧪 Run examples/llm_integration_example.py to see it in action
4. 🔧 Customize temp.py with your preferred LLM (OpenAI, Claude, etc.)
5. 🔐 Configure API keys in .env file
6. 🚀 Deploy to production
```
